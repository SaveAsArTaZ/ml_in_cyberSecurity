{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:28:17.437267Z",
     "start_time": "2025-04-15T18:28:16.811355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pickle\n",
    "import email_read_util"
   ],
   "id": "883f47b6dd5c1c2e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:28:17.448756Z",
     "start_time": "2025-04-15T18:28:17.446187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_DIR = 'trec07p/data/'\n",
    "LABELS_FILE = 'trec07p/full/index'\n",
    "TRAINING_SET_RATIO = 0.7"
   ],
   "id": "8506142f5274f4fc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:28:17.496535Z",
     "start_time": "2025-04-15T18:28:17.493823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = {}\n",
    "spam_words = set()\n",
    "ham_words = set()"
   ],
   "id": "d26d0e9220b006ce",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:28:17.614654Z",
     "start_time": "2025-04-15T18:28:17.541215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read the labels\n",
    "with open(LABELS_FILE) as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        label, key = line.split()\n",
    "        labels[key.split('/')[-1]] = 1 if label.lower() == 'ham' else 0"
   ],
   "id": "b3c0eb5aab84f528",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:28:17.698189Z",
     "start_time": "2025-04-15T18:28:17.659036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split corpus into train and test sets\n",
    "filelist = os.listdir(DATA_DIR)\n",
    "X_train = filelist[:int(len(filelist)*TRAINING_SET_RATIO)]\n",
    "X_test = filelist[int(len(filelist)*TRAINING_SET_RATIO):]"
   ],
   "id": "b2f1224d0d95bf69",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:28:20.379135Z",
     "start_time": "2025-04-15T18:28:17.710026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ],
   "id": "b3c33bc5eb205e86",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/artaz/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:28:20.398059Z",
     "start_time": "2025-04-15T18:28:20.394869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "from nltk import ngrams"
   ],
   "id": "52b6a1137d0988c2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5759be39a4041064"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:28:20.453143Z",
     "start_time": "2025-04-15T18:28:20.450063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parameters\n",
    "NGRAM_SIZE = 2  # Use bigrams (you can change this to 3 for trigrams, etc.)\n",
    "MIN_FREQ = 5    # Minimum frequency for n-grams to be considered"
   ],
   "id": "5c4d896a68abcc92",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:28:20.537513Z",
     "start_time": "2025-04-15T18:28:20.494147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Train the model - find frequent n-grams in spam\n",
    "if not os.path.exists('spam_ngrams.pkl'):\n",
    "    spam_ngram_counts = defaultdict(int)\n",
    "    ham_ngram_counts = defaultdict(int)\n",
    "\n",
    "    for filename in X_train:\n",
    "        path = os.path.join(DATA_DIR, filename)\n",
    "        if filename in labels:\n",
    "            label = labels[filename]\n",
    "            stems = email_read_util.load(path)\n",
    "            if not stems:\n",
    "                continue\n",
    "\n",
    "            # Generate n-grams\n",
    "            stem_ngrams = ngrams(stems, NGRAM_SIZE)\n",
    "\n",
    "            # Count n-grams based on label\n",
    "            if label == 0:  # Spam\n",
    "                for ng in stem_ngrams:\n",
    "                    spam_ngram_counts[ng] += 1\n",
    "            else:  # Ham\n",
    "                for ng in stem_ngrams:\n",
    "                    ham_ngram_counts[ng] += 1\n",
    "\n",
    "    # Filter n-grams that appear frequently in spam but rarely in ham\n",
    "    spam_indicative_ngrams = set()\n",
    "    for ng, count in spam_ngram_counts.items():\n",
    "        if count >= MIN_FREQ and ham_ngram_counts.get(ng, 0) < count/2:\n",
    "            spam_indicative_ngrams.add(ng)\n",
    "\n",
    "    pickle.dump(spam_indicative_ngrams, open('spam_ngrams.pkl', 'wb'))\n",
    "else:\n",
    "    spam_indicative_ngrams = pickle.load(open('spam_ngrams.pkl', 'rb'))\n",
    "\n",
    "\n",
    "print(f'Found {len(spam_indicative_ngrams)} spam-indicative {NGRAM_SIZE}-grams')\n"
   ],
   "id": "b10a2564eb250e61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57344 spam-indicative 2-grams\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:29:33.237139Z",
     "start_time": "2025-04-15T18:28:20.637892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Test the model\n",
    "fp = 0\n",
    "tp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "\n",
    "for filename in X_test:\n",
    "    path = os.path.join(DATA_DIR, filename)\n",
    "    if filename in labels:\n",
    "        true_label = labels[filename]\n",
    "        stems = email_read_util.load(path)\n",
    "        if not stems:\n",
    "            continue\n",
    "\n",
    "        # Generate n-grams for this email\n",
    "        stem_ngrams = set(ngrams(stems, NGRAM_SIZE))\n",
    "\n",
    "        # Check for spam-indicative n-grams\n",
    "        spam_score = len(stem_ngrams & spam_indicative_ngrams)\n",
    "\n",
    "        # Predict spam if any spam-indicative n-grams found\n",
    "        predicted_label = 0 if spam_score > 0 else 1\n",
    "\n",
    "        # Update confusion matrix\n",
    "        if true_label == 1 and predicted_label == 1:\n",
    "            tn += 1\n",
    "        elif true_label == 1 and predicted_label == 0:\n",
    "            fp += 1\n",
    "        elif true_label == 0 and predicted_label == 1:\n",
    "            fn += 1\n",
    "        elif true_label == 0 and predicted_label == 0:\n",
    "            tp += 1\n"
   ],
   "id": "475f72c79623711a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:29:33.376280Z",
     "start_time": "2025-04-15T18:29:33.371216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total = tp + tn + fp + fn\n",
    "accuracy = (tp + tn) / total\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "# Print formatted metrics\n",
    "print(\"\\nðŸ“Š Comprehensive Classification Metrics:\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\\n\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.1%}\")\n",
    "print(f\"Precision (Spam): {precision:.1%}\")\n",
    "print(f\"Recall (Spam): {recall:.1%}\")\n",
    "print(f\"F1 Score (Spam): {f1_score:.1%}\")\n",
    "print(f\"False Positive Rate: {false_positive_rate:.1%}\")\n",
    "print(f\"False Negative Rate: {false_negative_rate:.1%}\\n\")\n",
    "\n",
    "print(f\"Spam Detection Rate (Recall): {recall:.1%}\")\n",
    "print(f\"Ham Misclassification Rate (FPR): {false_positive_rate:.1%}\")\n",
    "print(f\"Total Emails Classified: {total}\")\n",
    "print(f\"Spam-Indicative {NGRAM_SIZE}-grams Used: {len(spam_indicative_ngrams)}\")"
   ],
   "id": "39bbe67e73375ad2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Comprehensive Classification Metrics:\n",
      "True Positives (TP): 11504\n",
      "True Negatives (TN): 3127\n",
      "False Positives (FP): 4309\n",
      "False Negatives (FN): 1874\n",
      "\n",
      "Accuracy: 70.3%\n",
      "Precision (Spam): 72.8%\n",
      "Recall (Spam): 86.0%\n",
      "F1 Score (Spam): 78.8%\n",
      "False Positive Rate: 57.9%\n",
      "False Negative Rate: 14.0%\n",
      "\n",
      "Spam Detection Rate (Recall): 86.0%\n",
      "Ham Misclassification Rate (FPR): 57.9%\n",
      "Total Emails Classified: 20814\n",
      "Spam-Indicative 2-grams Used: 57344\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
