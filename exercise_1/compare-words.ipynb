{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T09:10:19.435309Z",
     "start_time": "2025-04-15T09:10:18.636972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pickle\n",
    "import email_read_util\n",
    "from matplotlib import pyplot as plt\n"
   ],
   "id": "46d8dda2172eb7b9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T09:10:19.446742Z",
     "start_time": "2025-04-15T09:10:19.444550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_DIR = 'trec07p/data/'\n",
    "LABELS_FILE = 'trec07p/full/index'\n",
    "TRAINING_SET_RATIO = 0.7"
   ],
   "id": "51cc2e7412f8d208",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T09:10:19.497115Z",
     "start_time": "2025-04-15T09:10:19.494826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = {}\n",
    "spam_words = set()\n",
    "ham_words = set()"
   ],
   "id": "a838b61bdab17844",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T09:10:19.613798Z",
     "start_time": "2025-04-15T09:10:19.539455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read the labels\n",
    "with open(LABELS_FILE) as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        label, key = line.split()\n",
    "        labels[key.split('/')[-1]] = 1 if label.lower() == 'ham' else 0"
   ],
   "id": "b093e87eec03b2be",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T09:10:19.658802Z",
     "start_time": "2025-04-15T09:10:19.622399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split corpus into train and test sets\n",
    "filelist = os.listdir(DATA_DIR)\n",
    "X_train = filelist[:int(len(filelist)*TRAINING_SET_RATIO)]\n",
    "X_test = filelist[int(len(filelist)*TRAINING_SET_RATIO):]"
   ],
   "id": "b6abb949362192d2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T09:10:20.013471Z",
     "start_time": "2025-04-15T09:10:19.671743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ],
   "id": "bdeab3a73ea08712",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/artaz/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T09:10:20.391775Z",
     "start_time": "2025-04-15T09:10:20.032294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize data structures\n",
    "spam_word_counts = defaultdict(int)\n",
    "ham_word_counts = defaultdict(int)\n",
    "total_spam = 0\n",
    "total_ham = 0\n",
    "\n",
    "# Count word occurrences\n",
    "for filename in X_train:\n",
    "    path = os.path.join(DATA_DIR, filename)\n",
    "    if filename in labels:\n",
    "        label = labels[filename]\n",
    "        stems = email_read_util.load(path)\n",
    "        if not stems:\n",
    "            continue\n",
    "\n",
    "        if label == 0:  # Spam\n",
    "            total_spam += 1\n",
    "            for word in set(stems):\n",
    "                spam_word_counts[word] += 1\n",
    "        else:  # Ham\n",
    "            total_ham += 1\n",
    "            for word in set(stems):\n",
    "                ham_word_counts[word] += 1"
   ],
   "id": "c12207db865ce85a",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Initialize data structures\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m spam_word_counts \u001B[38;5;241m=\u001B[39m defaultdict(\u001B[38;5;28mint\u001B[39m)\n\u001B[1;32m      3\u001B[0m ham_word_counts \u001B[38;5;241m=\u001B[39m defaultdict(\u001B[38;5;28mint\u001B[39m)\n\u001B[1;32m      4\u001B[0m total_spam \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Calculate word statistics\n",
    "word_stats = {}\n",
    "all_words = set(spam_word_counts.keys()).union(set(ham_word_counts.keys()))\n",
    "for word in all_words:\n",
    "    spam_count = spam_word_counts.get(word, 0)\n",
    "    ham_count = ham_word_counts.get(word, 0)\n",
    "    spam_percent = (spam_count / total_spam) * 100\n",
    "    ham_percent = (ham_count / total_ham) * 100\n",
    "    word_stats[word] = (spam_percent, ham_percent)"
   ],
   "id": "820a4e5e63d5f6d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate different thresholds from 1% to 20%\n",
    "thresholds = range(1, 21)\n",
    "results = []\n",
    "\n",
    "for min_spam_percent in thresholds:\n",
    "    # Find words that meet the current threshold criteria\n",
    "    spam_words = set()\n",
    "    for word, (spam_p, ham_p) in word_stats.items():\n",
    "        if spam_p >= min_spam_percent:\n",
    "            spam_words.add(word)\n",
    "\n",
    "    # Test the model\n",
    "    tp = fp = fn = tn = 0\n",
    "\n",
    "    for filename in X_test:\n",
    "        path = os.path.join(DATA_DIR, filename)\n",
    "        if filename in labels:\n",
    "            true_label = labels[filename]\n",
    "            stems = email_read_util.load(path)\n",
    "            if not stems:\n",
    "                continue\n",
    "\n",
    "            # Check for spam words\n",
    "            stem_set = set(stems)\n",
    "            spam_score = len(stem_set & spam_words)\n",
    "\n",
    "            # Predict spam if any spam words found\n",
    "            predicted_label = 0 if spam_score > 0 else 1\n",
    "\n",
    "            # Update confusion matrix\n",
    "            if true_label == 1 and predicted_label == 1:\n",
    "                tn += 1\n",
    "            elif true_label == 1 and predicted_label == 0:\n",
    "                fp += 1\n",
    "            elif true_label == 0 and predicted_label == 1:\n",
    "                fn += 1\n",
    "            elif true_label == 0 and predicted_label == 0:\n",
    "                tp += 1\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    results.append({\n",
    "        'threshold': min_spam_percent,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'spam_words_count': len(spam_words)\n",
    "    })"
   ],
   "id": "fd07c97aec0daaf7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(thresholds, [r['accuracy'] for r in results], marker='o')\n",
    "plt.title('Accuracy vs Spam Percentage Threshold')\n",
    "plt.xlabel('Minimum Spam Percentage (%)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "\n",
    "# Precision\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(thresholds, [r['precision'] for r in results], marker='o', color='orange')\n",
    "plt.title('Precision vs Spam Percentage Threshold')\n",
    "plt.xlabel('Minimum Spam Percentage (%)')\n",
    "plt.ylabel('Precision')\n",
    "plt.grid(True)\n",
    "\n",
    "# Recall\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(thresholds, [r['recall'] for r in results], marker='o', color='green')\n",
    "plt.title('Recall vs Spam Percentage Threshold')\n",
    "plt.xlabel('Minimum Spam Percentage (%)')\n",
    "plt.ylabel('Recall')\n",
    "plt.grid(True)\n",
    "\n",
    "# F1 Score\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(thresholds, [r['f1'] for r in results], marker='o', color='red')\n",
    "plt.title('F1 Score vs Spam Percentage Threshold')\n",
    "plt.xlabel('Minimum Spam Percentage Threshold (%)')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\nPerformance Summary:\")\n",
    "print(\"Threshold% | Spam Words | Accuracy | Precision | Recall | F1 Score\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "for r in results:\n",
    "    print(f\"{r['threshold']:>9}% | {r['spam_words_count']:>10} | {r['accuracy']:.3f} | {r['precision']:.3f} | {r['recall']:.3f} | {r['f1']:.3f}\")"
   ],
   "id": "ed891ba1603ef549"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
