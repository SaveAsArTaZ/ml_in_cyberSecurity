{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import pickle\n",
    "import email_read_util"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "DATA_DIR = 'trec07p/data/'\n",
    "LABELS_FILE = 'trec07p/full/index'\n",
    "TRAINING_SET_RATIO = 0.7"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "labels = {}\n",
    "spam_words = set()\n",
    "ham_words = set()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Read the labels\n",
    "with open(LABELS_FILE) as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        label, key = line.split()\n",
    "        labels[key.split('/')[-1]] = 1 if label.lower() == 'ham' else 0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Split corpus into train and test sets\n",
    "filelist = os.listdir(DATA_DIR)\n",
    "X_train = filelist[:int(len(filelist)*TRAINING_SET_RATIO)]\n",
    "X_test = filelist[int(len(filelist)*TRAINING_SET_RATIO):]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T07:11:57.629547Z",
     "start_time": "2025-04-15T07:08:16.012269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parameters\n",
    "MIN_SPAM_PERCENT = 0.20  # حداقل حضور در اسپم\n",
    "MAX_HAM_PERCENT = 0.05   # حداکثر حضور در هم\n",
    "LAPLACE_SMOOTHING = 1    # برای جلوگیری از تقسیم بر صفر\n",
    "\n",
    "if not os.path.exists('spam_scores.pkl'):\n",
    "    spam_word_counts = defaultdict(int)\n",
    "    ham_word_counts = defaultdict(int)\n",
    "    total_spam = 0\n",
    "    total_ham = 0\n",
    "\n",
    "    # First pass: count words and total emails\n",
    "    for filename in X_train:\n",
    "        path = os.path.join(DATA_DIR, filename)\n",
    "        if filename in labels:\n",
    "            label = labels[filename]\n",
    "            stems = email_read_util.load(path)\n",
    "            if not stems:\n",
    "                continue\n",
    "\n",
    "            if label == 0:  # Spam\n",
    "                total_spam += 1\n",
    "                for word in set(stems):\n",
    "                    spam_word_counts[word] += 1\n",
    "            else:  # Ham\n",
    "                total_ham += 1\n",
    "                for word in set(stems):\n",
    "                    ham_word_counts[word] += 1\n",
    "\n",
    "    # Calculate spam scores for all words\n",
    "    word_scores = {}\n",
    "    for word in set(spam_word_counts.keys()).union(set(ham_word_counts.keys())):\n",
    "        spam_count = spam_word_counts.get(word, 0)\n",
    "        ham_count = ham_word_counts.get(word, 0)\n",
    "\n",
    "        # با استفاده از smoothing برای جلوگیری از تقسیم بر صفر\n",
    "        spam_prob = (spam_count + LAPLACE_SMOOTHING) / (total_spam + 2*LAPLACE_SMOOTHING)\n",
    "        ham_prob = (ham_count + LAPLACE_SMOOTHING) / (total_ham + 2*LAPLACE_SMOOTHING)\n",
    "\n",
    "        # محاسبه امتیاز اسپم به عنوان نسبت احتمال\n",
    "        word_scores[word] = spam_prob / (spam_prob + ham_prob)\n",
    "\n",
    "    pickle.dump(word_scores, open('spam_scores.pkl', 'wb'))\n",
    "else:\n",
    "    word_scores = pickle.load(open('spam_scores.pkl', 'rb'))\n",
    "\n",
    "print(f'Total spam emails in training: {total_spam}')\n",
    "print(f'Total ham emails in training: {total_ham}')\n",
    "\n",
    "# Test the model\n",
    "fp = 0\n",
    "tp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "THRESHOLD = 0.7  # آستانه برای تشخیص اسپم\n",
    "\n",
    "for filename in X_test:\n",
    "    path = os.path.join(DATA_DIR, filename)\n",
    "    if filename in labels:\n",
    "        true_label = labels[filename]\n",
    "        stems = email_read_util.load(path)\n",
    "        if not stems:\n",
    "            continue\n",
    "\n",
    "        # محاسبه امتیاز کلی ایمیل\n",
    "        email_score = 0\n",
    "        found_words = 0\n",
    "        for word in set(stems):\n",
    "            if word in word_scores:\n",
    "                email_score += word_scores[word]\n",
    "                found_words += 1\n",
    "\n",
    "        if found_words > 0:\n",
    "            email_score /= found_words  # میانگین امتیاز کلمات\n",
    "\n",
    "        # پیش‌بینی بر اساس آستانه\n",
    "        predicted_label = 0 if email_score > THRESHOLD else 1\n",
    "\n",
    "        # Update confusion matrix\n",
    "        if true_label == 1 and predicted_label == 1:\n",
    "            tn += 1\n",
    "        elif true_label == 1 and predicted_label == 0:\n",
    "            fp += 1\n",
    "        elif true_label == 0 and predicted_label == 1:\n",
    "            fn += 1\n",
    "        elif true_label == 0 and predicted_label == 0:\n",
    "            tp += 1\n",
    "\n",
    "# نمایش نتایج\n",
    "from IPython.display import HTML, display\n",
    "conf_matrix = [[tn, fp],\n",
    "               [fn, tp]]\n",
    "display(HTML('<table><tr>{}</tr></table>'.format(\n",
    "    '</tr><tr>'.join('<td>{}</td>'.format(\n",
    "        '</td><td>'.join(str(_) for _ in row))\n",
    "                     for row in conf_matrix))))\n",
    "\n",
    "count = tn + tp + fn + fp\n",
    "percent_matrix = [[\"{:.1%}\".format(tn/count), \"{:.1%}\".format(fp/count)],\n",
    "                  [\"{:.1%}\".format(fn/count), \"{:.1%}\".format(tp/count)]]\n",
    "display(HTML('<table><tr>{}</tr></table>'.format(\n",
    "    '</tr><tr>'.join('<td>{}</td>'.format(\n",
    "        '</td><td>'.join(str(_) for _ in row))\n",
    "                     for row in percent_matrix))))\n",
    "\n",
    "print(\"Classification accuracy: {}\".format(\"{:.1%}\".format((tp+tn)/count)))\n",
    "print(\"Precision (spam): {}\".format(\"{:.1%}\".format(tp/(tp+fp))))\n",
    "print(\"Recall (spam): {}\".format(\"{:.1%}\".format(tp/(tp+fn))))\n",
    "print(\"F1-score (spam): {}\".format(\"{:.1%}\".format(2*tp/(2*tp + fp + fn))))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total spam emails in training: 31134\n",
      "Total ham emails in training: 17615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<table><tr><td>7435</td><td>1</td></tr><tr><td>10178</td><td>3200</td></tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<table><tr><td>35.7%</td><td>0.0%</td></tr><tr><td>48.9%</td><td>15.4%</td></tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 51.1%\n",
      "Precision (spam): 100.0%\n",
      "Recall (spam): 23.9%\n",
      "F1-score (spam): 38.6%\n"
     ]
    }
   ],
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
